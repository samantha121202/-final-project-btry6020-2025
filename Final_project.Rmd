---
title: "Analysis of Student Data for BTRY 6020 Final Project"
author: "Samantha Davies"
date: "`r Sys.Date()`"
output:
  pdf_document:
    latex_engine: xelatex
    toc: true
    toc_depth: 2
    number_sections: true
documentclass: article
header-includes:
  - \usepackage[a4paper, total={6in, 8in}]{geometry}
  - \renewcommand{\contentsname}{Contents}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  width = 80
)
options(width = 80)

```

# Introduction

Students have varying levels of performance in school, and it is known that performance depends on a number of factors. Student demographics, such as race and ethnicity or family income are likely to have an influence on student performance in school and on exams. A model that can show this would improve equality within school systems because the level of additional help students who are disadvantaged at a baseline level could be identified and school systems worldwide could improve average scores on exams while also providing a better education to historically disadvantaged groups of students.

In this analysis, I used provided demographic variables as predictors for the student's math test score, which was also provided.

# Setup

```{r, message=FALSE, warning=FALSE, results='hide'}
# Install all necessary libraries for the analysis
library(ggplot2)
library(dplyr)
library(tidyr)
library(leaps)
library(car)
library(lmtest)

# Read in data, downloaded from Kaggle (see references for link)
data = read.csv("StudentsPerformance.csv")

```

# Exploratory Data Analysis

## Summary statistics of variables

```{r,warning=FALSE}

summary = summary(data)

# Table of summary statistics
summary_table = data.frame(
  Min = summary[1,],
  `1st Qu.` = summary[2,],
  Median = summary[3,],
  Mean = summary[4,],
  `3rd Qu.` = summary[5,],
  Max = summary[6,]
)
# These are the variables in the dataset I am using as well as the summary 
# statistics for each column:
summary_table

```

# Visualizations of distributions and relationships

```{r, warning=FALSE}

# Histogram and density plots for each column with continuous variables
  math_density = ggplot(data = data, aes_string(x = data$math.score)) +
    geom_histogram(aes(y = after_stat(density)), bins = 50, 
                   fill = "skyblue", color = "black") +
    ggtitle(paste("Distribution of math.score"))
  print(math_density)
  
  reading_density = ggplot(data = data, aes_string(x = data$reading.score)) +
    geom_histogram(aes(y = after_stat(density)), bins = 50, 
                   fill = "skyblue", color = "black") +
    ggtitle(paste("Distribution of reading.score"))
  print(reading_density)
  
   writing_density = ggplot(data = data, aes_string(x = data$writing.score)) +
    geom_histogram(aes(y = after_stat(density)), bins = 50, 
                   fill = "skyblue", color = "black") +
    ggtitle(paste("Distribution of writing.score"))
  print(writing_density)

```

## Visualize the categorical variables

```{r}
  ggplot(data, aes(x = gender)) + 
  geom_bar(fill = "skyblue") +
  ggtitle("Distribution of Gender")

  ggplot(data, aes(x = race.ethnicity)) + 
  geom_bar(fill = "skyblue") +
  ggtitle("Distribution of race.ethnicity")
  
  ggplot(data, aes(x = parental.level.of.education)) + 
  geom_bar(fill = "skyblue") +
  ggtitle("Distribution of parental.level.of.education")
  
  ggplot(data, aes(x = lunch)) + 
  geom_bar(fill = "skyblue") +
  ggtitle("Distribution of lunch")
  
  ggplot(data, aes(x = test.preparation.course)) + 
  geom_bar(fill = "skyblue") +
  ggtitle("Distribution of test.preparation.course")

```

## Pairs plot to visualize relationships between numerical variables

```{r}
pairs(data.frame(data$math.score, data$reading.score, 
                 data$writing.score))

```

### Identification of missing values and outliers

## For math.score
```{r, warning=FALSE}
# Find Q1, Q3, and IQR
Q1 = quantile(data$math.score, 0.25)
Q3 = quantile(data$math.score, 0.75)
IQR = Q3 - Q1
  
# Find lower and upper bounds
lower_math = Q1 - 1.5 * IQR
upper_math = Q3 + 1.5 * IQR
  
# Filter outliers
math_score_outliers = data %>%
  filter(math.score < lower_math | math.score > upper_math)

```

This table shows the information for all students whose math scores were 
outliers compared to the whole set of math scores:

```{r}
print(math_score_outliers)
```



## For writing.score
```{r}

# Find Q1, Q3, and IQR
Q1 = quantile(data$writing.score, 0.25)
Q3 = quantile(data$writing.score, 0.75)
IQR = Q3 - Q1
  
# Find lower and upper bounds
lower_writing = Q1 - 1.5 * IQR
upper_writing = Q3 + 1.5 * IQR
  
# Filter outliers
writing_score_outliers = data %>%
  filter(writing.score < lower_writing | writing.score > upper_writing)
```

This table shows the information for all students whose writing scores were 
outliers compared to the whole set of math scores:

```{r}
print(writing_score_outliers)
```


## For reading.score
```{r}

# Find Q1, Q3, and IQR
Q1 = quantile(data$reading.score, 0.25)
Q3 = quantile(data$reading.score, 0.75)
IQR = Q3 - Q1
  
# Find lower and upper bounds
lower_reading = Q1 - 1.5 * IQR
upper_reading = Q3 + 1.5 * IQR
  
# Filter outliers
reading_score_outliers = data %>%
  filter(reading.score < lower_reading | reading.score > upper_reading)

```

This table shows the information for all students whose reading scores were 
outliers compared to the whole set of math scores
```{r}
print(reading_score_outliers)
```


## Determine if there are any missing values
```{r}
print("Are there any NA vlaues in the dataset?")
anyNA(data)

```
This dataset has no missing values.


# Data cleaning and preprocessing steps

Remove outliers, as determined from "Identification of outliers" section above
```{r,warning=FALSE}
data_clean = data %>%
  filter(
    math.score >= lower_math & math.score <= upper_math,
    reading.score >= lower_reading & reading.score <= upper_reading,
    writing.score >= lower_writing & writing.score <= upper_writing
  )

summary = summary(data_clean)

summary_table_clean = data.frame(
  Min = summary[1,],
  `1st Qu.` = summary[2,],
  Median = summary[3,],
  Mean = summary[4,],
  `3rd Qu.` = summary[5,],
  Max = summary[6,]
)

```

After removing outliers, the minimum, 1st quartile, mean, and 3rd quartile 
values have changed for some or all of the reading, writing, and math test 
scores. The median and maximum values did not change for any continuous 
variables.

```{r}
print(summary_table_clean)
```

In case there are any duplicates
```{r}
data_clean = data_clean[!duplicated(data_clean), ]

```


Convert categorical variables to factors and continuous variables to numeric
```{r}

#See data type for each column
str(data_clean)

# Convert categorical variables to factors
data_clean$gender = as.factor(data_clean$gender)
data_clean$race.ethnicity = as.factor(data_clean$race.ethnicity)
data_clean$parental.level.of.education = 
  as.factor(data_clean$parental.level.of.education)
data_clean$lunch = as.factor(data_clean$lunch)
data_clean$test.preparation.course = 
  as.factor(data_clean$test.preparation.course)

# Convert continuous variables to numeric
data_clean$math.score = as.numeric(data_clean$math.score)
data_clean$reading.score = as.numeric(data_clean$reading.score)
data_clean$writing.score = as.numeric(data_clean$writing.score)


# Assign completed/not completed prep course to 1/0 for true or false
data_clean$test.preparation.course = 
  ifelse(data_clean$test.preparation.course == "completed", 1, 0)

# Assign standard or reduced lunch to 1/0 for true or false
data_clean$lunch = ifelse(data_clean$lunch == "standard", 1, 0)

# Assign male or female to 1/0 for male or female
data_clean$gender = ifelse(data_clean$gender == "male", 1, 0)

```

# Variable Selection & Hypothesis Testing

## Implement at least two different variable selection techniques


Set up model selection by creating empty and full models
```{r,warning=FALSE}

#empty model as baseline
empty = lm(math.score ~ 1, data = data_clean)

#Full model
model = lm(math.score ~ gender + race.ethnicity + parental.level.of.education 
           + lunch + test.preparation.course,
           data = data_clean)
```

Conduct forward selection using AIC
```{r}
forward_model = step(empty,
                      scope = list(lower = empty, upper = model),
                      direction = "forward")

#View variables included in forward-selected model
print("The forward selectoion produces the model:")
formula(forward_model)

```
This model retains all possible variables.

Conduct branch and bound selection
```{r}
bnb_model = regsubsets(math.score ~ gender + race.ethnicity + 
                         parental.level.of.education + 
                         lunch + test.preparation.course,
                           data = data_clean)

# Get the summary of the subset model
bnb_summary = summary(bnb_model)


# Extract all possible combinations' BIC
#The possible BIC values from models analyzed using branch and bound are:
bnb_summary$bic


# View variables included in ideal model
# The variables included in the ideal model chosen with the branch and bound 
# model are:
bnb_summary$which[which.min(bnb_summary$bic), ]
```

This model retains all possible variables, and is therefore identical to the 
forward selection model.


Therefore, the model I will use is math.score ~ lunch + race.ethnicity + 
test.preparation.course + gender + parental.level.of.education.


## Validate model using an appropriate cross-validation technique and assess model performance with rmse and R2

I am using train/test split (80/20) to validate my model's performance because there is a lot of data (1000 rows), and I am not concerned with the exact precision of this model, but rather with its ability to obtain a pretty good value for math score.

```{r, warning=FALSE}

set.seed(123)
train_index = sample(1:nrow(data_clean), 0.8 * nrow(data_clean))
test = data_clean[-train_index, ]

predictions = predict(model, newdata = test)

# Evaluate performance
actual = test$math.score

rmse = sqrt(mean((actual - predictions)^2))
rmse

r2 = 1 - sum((actual - predictions)^2) / sum((actual - mean(actual))^2)
r2

```

The model's prediction is, on average, 12.8 points off of the value it should 
have predicted. This seems promising to be able to pinpoint students who will 
need the most help!


The R2 of this model (both in cross-validation and entire model) is low (0.24, when 1 is ideal). This means the model is likely underfitting, and there is a need for more predictors. Unfortunately, given the goals of this project, additional available data do not exist to include in the model; we have included all available predictors (besides other test scores, which would not contribute to achieving the goals of this project).

## Perform hypothesis tests on coefficients

```{r,warning=FALSE}

summary = summary(model)
alpha = 0.05


   #Coefficient lunch
#H0: coefficient == 0
#HA: coefficient != 0
#a = 0.05

p_value = summary$coefficients["lunch", "Pr(>|t|)"]
p_value
```
Reject H0: The coefficient for lunch is statistically significant.

```{r,warning=FALSE}

   #Coefficient race.ethnicity
#H0: coefficient == 0
#HA: coefficient != 0
#a = 0.05

p_value = summary$coefficients["race.ethnicitygroup D", "Pr(>|t|)"]
p_value
```
Reject H0: At least one of the coefficients for race.ethnicity is 
statistically significant.

```{r,warning=FALSE}

   #Coefficient test.preparation.course
#H0: coefficient == 0
#HA: coefficient != 0
#a = 0.05

p_value = summary$coefficients["test.preparation.course", "Pr(>|t|)"]
p_value
```
Reject H0: The coefficient for test.preparation.course is statistically 
significant.


```{r,warning=FALSE}

   #Coefficient gender
#H0: coefficient == 0
#HA: coefficient != 0
#a = 0.05

p_value = summary$coefficients["gender", "Pr(>|t|)"]
p_value
```
Reject H0: The coefficient for gender is statistically significant.

```{r,warning=FALSE}
   #Coefficient parental.level.of.education
#H0: coefficient == 0
#HA: coefficient != 0
#a = 0.05

p_value = summary$coefficients["parental.level.of.educationhigh school", 
                               "Pr(>|t|)"]
p_value
```
Reject H0: At least of the coefficients for parental.level.of.education is 
statistically significant.


# Regression Assumptions Verification

## Linearity and homoscedasticity (constant variance of residuals) assessment and independence of observations

```{r,warning=FALSE}
plot(model, which = 1)
```
The plot of fitted values vs residuals looks very random. There is no apparent 
pattern within these points. Therefore, the assumption of linearity holds for 
this model.


This plot looks good in regards to variance of the residuals. points appear 
evenly scattered above and below the '0' line across all fitted values. 
Therefore, the assumption of homoscedasticity holds for this model.

Also per the residuals vs fitted plot, it appears that the independence of 
observations assumption holds because there is no trend in residuals as fitted 
values increase. There was no specified sampling order, and this data is not 
time-dependent, so there is no reason to believe independence of observation 
does not hold. It would be important to know what sampling method was used, 
though, to obtain data.


We can also check independence with the durbin-watson test
```{r}
dwtest(model)
```

The p-value is >> alpha (0.05), so we do not reject the null hypothesis, and 
therefore will assume that residuals are not autocorrelated.


## Normality of residuals

```{r,warning=FALSE}

qqPlot(residuals(model), main = "Q-Q Plot")

```
Residuals appear to be slightly skewed, but probably not too much to 
worry about. I also tried transforming math.score in case that could further 
improve the normality of residuals, but all attempted transformations worsened 
the skewness. I tried log(), exp(), and squaring math.score.")


log() y did not improve residuals

squaring y did not improve residuals

exp(y) did not improve residuals


## Multicollinearity assessment

We can use the variance inflation factor (VIF) to test for multicolinearity. 
VIF of 1-2 is ideal.

```{r}
vif(model)
```
All VIF vlaues are very close to 1, so we can conclude that the 
multicolinearity assumption is met for this model.


# Feature Impact Analysis

## Quantify and interpret the impact of each feature on the target and Provide confidence intervals for significant coefficients

```{r,warning=FALSE}

coeffs = summary$coefficients
coeffs
```


The impact of gender on math.score is 4.7. This means that, holding all else 
constant, a male student would be associated with an average of 4.7(+- 0.8) 
more points of their math score than a female student.

The impact of lunch on math.score is 10.0. This means that, holding all else 
constant, a  student who receives standard lunch prices would be associated 
with an average of 10.0(+- 0.8) more points of their math score than a student 
who receives reduced lunch prices.

The impact of prep courses on math.score is 4.9. This means that, holding all 
else constant, a student who completed a prep course would be associated with 
an average of 4.9(+- 0.8) more points of their math score than a student who 
did not complete a prep course.

The impact of a student being in race/ethnicity group D or E on math.score is 
5.2 and 10.3, respectively. This means that, holding all else constant, a 
student who was in race/ethnicity groups D or E would be associated with an 
average of 5.2(+-1.6) and 10.3(+-1.7) more points of their math score than a 
student in race/ethnicity group A.

The impact of a student's parental level of education being 'high school' or 
'some high school' on math.score is -4.5 and -3.4, respectively. This means 
that, holding all else constant, a student whose parent completed high school 
or some high school would be associated with an average of 4.5(+-1.3) and 
3.4(+-1.3) LESS points of their math score than a student in the reference 
category, whose parent completed an associates degree.


# Conclusions

From this analysis, I have demonstrated that gender, race, parental education, lunch price, and test prep courses all significantly factor into determining a student's math test score. The overall R2 of 0.23 means that there are other factors that need to be considered to accurately predict a students's test score, though. These factors could include parents age, number of siblings the student has, talkativeness of the student. In a larger survey, maybe a short math pre-test could be administered as well to assess a student's capabilities.

# References

Data was sources from Kaggle.com. The dataset was called 'students-performance in exams', and was uploaded by Jakki Seshapanpu.

The online dataset can be found at the following link:

<https://www.kaggle.com/datasets/spscientist/students-performance-in-exams>
